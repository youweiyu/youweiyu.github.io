<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Some ST Enlightenments</title>
      <link href="/2025/10/12/st_idea/"/>
      <url>/2025/10/12/st_idea/</url>
      
        <content type="html"><![CDATA[<h1 id="Preparation-for-ST-Idea"><a href="#Preparation-for-ST-Idea" class="headerlink" title="Preparation for ST Idea"></a>Preparation for ST Idea</h1><h2 id="DCGLC"><a href="#DCGLC" class="headerlink" title="DCGLC"></a>DCGLC</h2><ul><li><strong>标题</strong>：Dual Contrastive Graph-Level Clustering with Multiple Cluster Perspectives Alignment</li><li><strong>作者</strong>：National University of Singapore</li><li><strong>发表会议&#x2F;期刊</strong>：IJCAI</li><li><strong>年份</strong>：2024</li><li><strong>链接</strong>：<a href="https://www.ijcai.org/proceedings/2024/0417.pdf">DCGLC</a></li></ul><h3 id="Generalization"><a href="#Generalization" class="headerlink" title="Generalization"></a>Generalization</h3><ul><li><strong>Main Contribution</strong>:<ol><li>DCGLC，一种端到端的聚类方法，它统一了图对比学习的优化与不同聚类视角的信息整合。</li><li>一种聚类视角对比机制来对齐聚类信息，通过同时考虑图之间的几何和结构关系，从而产生更可靠的聚类分配。</li><li>DCGLC在图级聚类任务上优于最先进的基线方法。</li></ol></li></ul><h3 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h3><ul><li><p><strong>总体框架</strong>：<br>  <img src="/img/st_idea/0.png" alt="Generalization"></p></li><li><p><strong>方法概述</strong>：</p><ol><li>general problem<br>  <img src="/img/st_idea/1.png" alt="Generalization"></li><li>loss on graph-level representation<br>  <img src="/img/st_idea/2.png" alt="Generalization"></li><li>two clustering heads<br>- Euclidian-based and subspace-based<br> <img src="/img/st_idea/3.png" alt="Generalization"><br>- Enhancement of clustering reliability<br> <img src="/img/st_idea/4.png" alt="Generalization"><br>- alignment and contrastive loss<br> <img src="/img/st_idea/5.png" alt="Generalization"></li></ol></li></ul><h3 id="ST-Idea"><a href="#ST-Idea" class="headerlink" title="ST Idea"></a>ST Idea</h3><p><strong>1. 通过对比机制来对齐来自不同聚类视角的聚类信息</strong><br><strong>2. 训练时引入了明确的聚类目标 <em>KL散度</em>(cluster assignment distribution and refined assignment distribution)</strong></p><h2 id="MRePath"><a href="#MRePath" class="headerlink" title="MRePath"></a>MRePath</h2><ul><li><strong>标题</strong>：Multimodal Cancer Survival Analysis via Hypergraph Learning with Cross-Modality Rebalance</li><li><strong>作者</strong>：Harbin Institute of Technology</li><li><strong>发表会议&#x2F;期刊</strong>：IJCAI</li><li><strong>年份</strong>：2025</li><li><strong>链接</strong>：<a href="https://www.ijcai.org/proceedings/2025/201">MRePath</a></li></ul><h3 id="Generalization-1"><a href="#Generalization-1" class="headerlink" title="Generalization"></a>Generalization</h3><ul><li><strong>Main Contribution</strong>:<ol><li>提出了一个多模态框架MRePath，以解决WSIs生存分析中基于MIL的信息丢失和病理-基因组模态不平衡的挑战。</li><li>在拓扑和特征空间上构建了一个包含sheaf超图的超图学习框架，以捕捉上下文和层次细节，同时增强模型区分不同类型信息的能力。</li><li>引入了一种模态重平衡方法，包括动态加权机制和交互式对齐融合，以调整两种模态对最终风险预测的贡献。</li><li>在五个公共数据集上的定性和定量实验证明了我们模型的优越性，比先进方法提高了3.4%。</li></ol></li></ul><h3 id="Content-1"><a href="#Content-1" class="headerlink" title="Content"></a>Content</h3><ul><li><p><strong>总体框架</strong>：<br>  <img src="/img/st_idea/6.png" alt="Generalization"></p></li><li><p><strong>Three Stages</strong>:<br><strong>feature extraction, hypergraph learning, and modality rebalance</strong></p><ul><li><p>feature extraction:<br>$$ P \in \mathbb{R}^{N \times d} \quad &amp; \quad G \in \mathbb{R}^{M \times d} $$</p></li><li><p>hypergraph learning:<br><img src="/img/st_idea/7.png" alt="Generalization"></p></li><li><p>modality rebalance:</p><ul><li>Mono-confidence<br><img src="/img/st_idea/8.png" alt="Generalization"></li><li>Holo-confidence<br><img src="/img/st_idea/9.png" alt="Generalization"></li><li>Final Weights<br><img src="/img/st_idea/10.png" alt="Generalization"><br>$$<br>P_w &#x3D; \omega_p P_h\quad and \quad G_w &#x3D; \omega_g G<br>$$</li><li>Interactive Alignment Fusion(self-attention)<br><img src="/img/st_idea/11.png" alt="Generalization"></li></ul></li><li><p>target(略):<br><img src="/img/st_idea/12.png" alt="Generalization"></p></li></ul></li></ul><h3 id="ST-Idea-1"><a href="#ST-Idea-1" class="headerlink" title="ST Idea"></a>ST Idea</h3><p><strong>1. 动态权重机制：Mono-confidence &amp; Holo-confidence</strong><br><strong>2. 交互式对齐融合：co-attention &amp; residual connection</strong></p><h2 id="完结撒花"><a href="#完结撒花" class="headerlink" title="完结撒花"></a><strong>完结撒花</strong></h2><hr>]]></content>
      
      
      <categories>
          
          <category> work1 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>stMMR</title>
      <link href="/2025/10/05/stMMR/"/>
      <url>/2025/10/05/stMMR/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="stMMR"><a href="#stMMR" class="headerlink" title="stMMR"></a>stMMR</h2><ul><li><strong>标题</strong>：stMMR: accurate and robust saptial domain identification from spatially resolved transcriptomics with multimodal feature representation</li><li><strong>作者</strong>：Shandong University</li><li><strong>发表会议&#x2F;期刊</strong>：GigaScience</li><li><strong>年份</strong>：2024</li><li><strong>链接</strong>：<a href="https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giae089/7912109?login=false">stMMR</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><strong>Motivation</strong>:<br><em>融合多模态困难，多模态数据间具有显著异质性，而且在数据尺度和分辨率上存在差异</em></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><p><strong>总体框架</strong>：<br><strong>3 steps: <em>multimodal feature embedding</em>, <em>feature fusion</em>, and <em>feature reconstruction</em></strong><br><img src="/img/stMMR/0.png" alt="Generalization"></p></li><li><p>方法概述：</p><ol><li><p><strong>Multimodal feature embedding</strong></p><ul><li><p>gene expression: $ G \in \mathbb{R}^{n \times p} $ (n spots, p genes)</p></li><li><p>histological image: $ H \in \mathbb{R}^{n \times m} $ (m image features)</p></li><li><p>spatial location: 如图构建无向加权图<br> <img src="/img/stMMR/1.png" alt="Graph"></p></li><li><p>2层GCN编码器进行图像特征<em>H</em> 和 基因表达特征<em>G</em> 的消息传递与聚合($E^0&#x3D;H, E^0&#x3D;G$,输出$E_H和E_G$)：<br> <img src="/img/stMMR/2.png" alt="GCN"></p></li></ul></li><li><p><strong>Feature fusion</strong></p><ul><li><p>单模态内($E_H和E_G$)spots之间的全局关系(a normalized attention module),输出$E_{AH}和E_{AG}$<br> <img src="/img/stMMR/3.png" alt="Attention"></p></li><li><p>全连接降维，全连接融合，Loss，三部分整合<br> <img src="/img/stMMR/4.png" alt="Fusion"><br> <img src="/img/stMMR/5.png" alt="Fusion"></p></li></ul></li><li><p><strong>Feature reconstruction</strong></p><ul><li>ZINB模型重构基因表达<br> <img src="/img/stMMR/6.png" alt="ZINB"></li><li>MSE重构图像特征<br> <img src="/img/stMMR/7.png" alt="MSE"></li></ul></li><li><p><strong>Objective function</strong><br> <img src="/img/stMMR/8.png" alt="Objective"></p></li></ol></li></ul><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><ol><li>stMMR enhances detection of stratified architectural patterns in human dorsolateral prefrontal cortex tissue</li><li>stMMR enhances spatial gene expression profiling and structural characterization</li><li>stMMR deciphers evolving cell lineage structures in the chicken heart ST dataset</li><li>stMMR accurately identifies tumor region in human breast cancer</li><li>stMMR dissects cell-type differences in a lung cancer SRT dataset based on NanoString technology</li></ol><h2 id="完结撒花"><a href="#完结撒花" class="headerlink" title="完结撒花"></a>完结撒花</h2><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bering</title>
      <link href="/2025/09/25/Bering/"/>
      <url>/2025/09/25/Bering/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="Bering"><a href="#Bering" class="headerlink" title="Bering"></a>Bering</h2><ul><li><strong>标题</strong>：Bering: joint cell segmentation and annotation for spatial transcriptomics with transferred graph embeddings</li><li><strong>作者</strong>：Harvard University</li><li><strong>发表会议&#x2F;期刊</strong>：Nature Communications</li><li><strong>年份</strong>：2025</li><li><strong>链接</strong>：<a href="https://doi.org/10.1038/s41467-025-60898-9">Bering</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><p><strong>Motivation</strong>:<br><em>Some tissues have densely packed cells with unclear boundaries, making it difficult to perform accurate segmentation</em></p></li><li><p><strong>Task</strong>:<br><em>Cell segmentation and annotation for spatial transcriptomics</em></p></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><strong>总体框架</strong>：</li></ul><p><img src="/img/Bering/0.png" alt="Generalization"></p><ul><li>方法概述：<ol><li><p>图构建，NGC<br>  <img src="/img/Bering/1.png" alt="Generalization"></p></li><li><p>图卷积和全连接网络<br>  <img src="/img/Bering/2.png" alt="Generalization"></p></li><li><p>节点分类<br>  <img src="/img/Bering/3.png" alt="Generalization"></p></li><li><p>边嵌入由三部分组成<br>- node representation<br><img src="/img/Bering/4.png" alt="Generalization"><br>- distance kernels($\mu_d, \sigma_d$可学习参数)<br><img src="/img/Bering/5.png" alt="Generalization"><br>- image representation(使用CNN+SPP,边作为对角线图像)<br><img src="/img/Bering/6.png" alt="Generalization"><br><em>Edge embedding</em>:<br><img src="/img/Bering/7.png" alt="Generalization"><br><em>Edge classification</em>（预测边标签，是否同一个细胞内）:<br><img src="/img/Bering/8.png" alt="Generalization"><br><em>聚类算法划分细胞</em>（Leiden算法）:<br><img src="/img/Bering/9.png" alt="Generalization"></p></li><li><p>Other details</p><ul><li>cell type annotation details</li><li>transfer learning</li><li>NGC Matrix</li><li>Generation of validation data: FOVs</li></ul></li></ol></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IE-HERCL</title>
      <link href="/2025/09/23/IE-HERCL/"/>
      <url>/2025/09/23/IE-HERCL/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="IE-HERCL"><a href="#IE-HERCL" class="headerlink" title="IE-HERCL"></a>IE-HERCL</h2><ul><li><strong>标题</strong>：Image-Enhanced Hybrid Encoding with Reinforced Contrastive Learning for Spatial Domain Identification in Spatial Transcriptomics</li><li><strong>作者</strong>：Central South University</li><li><strong>发表会议&#x2F;期刊</strong>：IJCAI</li><li><strong>年份</strong>：2025</li><li><strong>链接</strong>：<a href="https://www.ijcai.org/proceedings/2025/0864.pdf">IE-HERCL</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><p><strong>Motivation</strong>:</p><p>  <em>Exisisting methods fail to account for complex interdependencies between modalities.</em></p></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><strong>总体框架</strong>：</li></ul><p><img src="/img/IE-HERCL/0.png" alt="Generalization"></p><ul><li><p>方法概述：</p><ol><li><p>Multimodal Feature Representation Learning</p><ul><li><p>utilize AE to extract &amp; Loss function L_rec:</p><p>$$<br>L^g_{rec} &#x3D; | X_{g,i} - f^g_{\theta_d}(f^g_{\theta_e}(X_{g,i})) |^2_F<br>$$</p></li><li><p>ultilize ResNet50 to extract $Z_{net}$ then use AE:<br><img src="/img/IE-HERCL/8.png" alt="ot"></p><!-- $$L_{rec}^{img} = \| Z_{net,i} - f^{img}_{\theta_d}(f^{img}_{\theta_e}(Z_{net,i})) \|^2_F$$ --></li><li><p>GraphSAGE encoder:</p><p>$$<br>Z^v_i &#x3D; \sigma(W_e \cdot \text{Concat}(X_i, \text{Aggregate}({X_j \mid j \in N(i)})))<br>$$</p></li><li><p>intra-modal attention &amp; cross-modal attention:</p><ul><li><p><strong>Intra-modal attention</strong>:<br>$$<br>Z_f^g &#x3D; \alpha_{ae_g} Z_g + \alpha_{gs_g} Z_{gs}^g<br>$$</p><p>$$<br>Z_f^{img} &#x3D; \alpha_{ae}^{img} Z_{img} + \alpha_{gs_img} Z^{img}_{gs}<br>$$</p></li><li><p><strong>Cross-modal attention</strong>:<br>  $$<br>  Z &#x3D; \beta_{g} Z^g_f + \beta_{img} Z^{img}_f<br>  $$</p></li></ul></li><li><p>Reconstruction:</p></li></ul><p> $$<br> \hat{X}_{g,i} &#x3D; \sigma(W_d \cdot \text{Concat}(Z_i, \text{Aggregate}({Z_j \mid j \in N(i)})))<br> $$</p><p> $$<br> L_{rec}^{gene} &#x3D; | X_{g,i} - \hat{X}_{g,i} |^2_F<br> $$</p></li><li><p>Negative Sample Mitigation Strategy in Contrastive Learning</p><ul><li>contrastive loss :<br> <img src="/img/IE-HERCL/1.png" alt="Generalization"><br> <img src="/img/IE-HERCL/2.png" alt="Generalization"></li></ul></li><li><p>Optimal Transport-Based Representation Optimization</p><ul><li><p>Clustering and Auxiliary Distributions<br> <img src="/img/IE-HERCL/3.png" alt="Generalization"></p></li><li><p>Optimal Transport Objective<br> <img src="/img/IE-HERCL/4.png" alt="ot"><br> <img src="/img/IE-HERCL/5.png" alt="ot"></p></li><li><p>借鉴way博客补充最优传输的思想：<br> <img src="/img/IE-HERCL/7.png" alt="ot"></p></li><li><p>Overall Optimization Objective<br> <img src="/img/IE-HERCL/6.png" alt="ot"></p></li></ul></li></ol></li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul><li>Evaluation Metrics：<ul><li>调整兰德指数(ARI)、标准化互信息(NMI)、调整互信息(AMI)、Fowlkes-Mallows指数(FMI)和同质性评分(HS)</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>stLearn</title>
      <link href="/2025/09/22/stLearn/"/>
      <url>/2025/09/22/stLearn/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="stLearn"><a href="#stLearn" class="headerlink" title="stLearn"></a>stLearn</h2><ul><li><strong>标题</strong>：Robust mapping of spatiotemporal trajectories and cell–cell interactions in healthy and diseased tissues</li><li><strong>作者</strong>：The University of Queensland</li><li><strong>发表会议&#x2F;期刊</strong>：Nature Communications</li><li><strong>年份</strong>：2023</li><li><strong>链接</strong>：<a href="https://doi.org/10.1038/s41467-023-43120-6">stLearn</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><p><strong>Motivation</strong>:</p><ol><li>the (re)construction of spatio-temporal trajectories</li><li>the study of cell–cell interactions</li><li>the improvement of spatial data quality by imputation</li></ol></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><p><strong>总体框架</strong>：</p>  <div align="center"><p>  <img src="/img/stLearn/0.png" alt="Generalization"></p>  </div></li><li><p>方法概述：</p><ol><li><p>pseudo-time-space (PSTS) for <strong>spatio-temporal trajectory inference</strong></p> <div align="center"><p> <img src="/img/stLearn/1.png" alt="Generalization"></p> </div><ol><li><p>DPT 与 Space 融合的算法</p></li><li><p><strong>伪时间距离Dpt</strong>:</p> <div align="center"><p> <img src="/img/stLearn/2.png" alt="Generalization"></p> </div></li><li><p><strong>空间距离Ds和伪时空距离Dpts</strong>:</p> <div align="center"><p> <img src="/img/stLearn/3.png" alt="Generalization"></p> </div></li></ol></li><li><p>spatially-constrained two-level permutation (SCTP) test</p> <div align="center"><p> <img src="/img/stLearn/4.png" alt="Generalization"></p> </div></li><li><p>spatial graph-based imputation method with neural network (stSME)</p> <div align="center"><p> <img src="/img/stLearn/5.png" alt="Generalization"></p> </div></li></ol></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GraphST</title>
      <link href="/2025/09/21/GraphST/"/>
      <url>/2025/09/21/GraphST/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="GraphST"><a href="#GraphST" class="headerlink" title="GraphST"></a>GraphST</h2><ul><li><strong>标题</strong>：Spatially informed clustering, integration,and deconvolution of spatial transcriptomics with GraphST</li><li><strong>作者</strong>：National University of Singapore (NUS)</li><li><strong>发表会议&#x2F;期刊</strong>：Nature Communications</li><li><strong>年份</strong>：2023</li><li><strong>链接</strong>：<a href="https://www.nature.com/articles/s41467-023-36796-3">GraphST</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><strong>Motivation</strong>:<ol><li>反卷积未利用空间信息</li><li>多样本整合未利用空间信息</li></ol></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><p><strong>总体框架</strong>：</p>  <div align="center"><p>  <img src="/img/GraphST/0.png" alt="Generalization"></p>  </div></li><li><p>方法概述：</p><ol><li><p><strong>graph self-supervised contrastive learning framework</strong>：</p><ul><li>data augmentation</li><li>GNN-based encoder for representation learning</li></ul> <div align="center"><p> <img src="/img/GraphST/1.png" alt="Generalization"></p> </div><ul><li>self-supervised contrastive learning for representation refinement</li></ul> <div align="center"><p> <img src="/img/GraphST/2.png" alt="Generalization"><br> <img src="/img/GraphST/3.png" alt="Generalization"><br> <img src="/img/GraphST/4.png" alt="Generalization"></p> </div></li><li><p><strong>Vertical and horizontal integration of multiple tissues via implicit batch effect correction</strong>(By PASTE)</p></li><li><p><strong>Spatially informed contrastive learning for scRNA-seq and ST data integration</strong></p> <div align="center"><p> <img src="/img/GraphST/5.png" alt="Generalization"><br> <img src="/img/GraphST/6.png" alt="Generalization"></p> </div><ol><li>Spot-targeted annotation transfer</li><li>Domain-targeted annotation transfer</li></ol> <div align="center"><p> <img src="/img/GraphST/7.png" alt="Generalization"><br> <img src="/img/GraphST/8.png" alt="Generalization"></p> </div></li></ol></li></ul><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ol><li>Spatial clustering</li><li>Multi-sample integration</li><li>ST and scRNA-seq integration</li></ol><h2 id="完结撒花"><a href="#完结撒花" class="headerlink" title="完结撒花"></a>完结撒花</h2><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepST</title>
      <link href="/2025/09/21/DeepST/"/>
      <url>/2025/09/21/DeepST/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="DeepST"><a href="#DeepST" class="headerlink" title="DeepST"></a>DeepST</h2><ul><li><strong>标题</strong>：DeepST: identifying spatial domains in spatial transcriptomics by deep learning</li><li><strong>作者</strong>：Harbin Institute of Technology</li><li><strong>发表会议&#x2F;期刊</strong>：Nucleic Acids Research</li><li><strong>年份</strong>：2022</li><li><strong>链接</strong>：<a href="https://academic.oup.com/nar/article/50/22/e131/6761985">DeepST</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><strong>Motivation</strong>:<ol><li>先前方法主要依赖线性主成分分析来提取基因表达的高变特征，因此无法建模复杂的非线性相互作用</li><li>未充分利用空间信息，且在预测组织结构方面存在局限</li><li>大多数分析大量ST数据的空间方法无法正确校正批次效应，且不能处理其他空间组学数据，使其通用性不足</li></ol></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><p><strong>总体框架</strong>：</p>  <div align="center"><p>  <img src="/img/DeepST/0.png" alt="Generalization"></p>  </div></li><li><p>方法概述：</p><ol><li><p><strong>Spatial data augmentation</strong>(平滑补偿机制):</p><ul><li>基因表达相关性（GCij）​​：基于标准化后的余弦距离计算点对间表达谱相似性；</li><li>形态学相似性（MSij）​​：<ul><li>从H&amp;E图像提取局部区块，经数据增强（旋转、锐化等）后通过预训练CNN（如Inception v3）提取2048维特征；</li><li>使用PCA降维至50维主成分，最终通过余弦距离量化形态相似性；</li></ul></li><li>空间邻近性（SWij）​​：基于坐标计算点间距离，定义半径γ（最近4点距离均值+方差）作为邻居判定阈值。</li></ul> <div align="center"><p> <img src="/img/DeepST/1.png" alt="Generalization"></p> </div></li><li><p><strong>Graph construction</strong>:</p><ul><li>基于空间坐标计算spots间距离，使用BallTree算法，默认top12为邻居，构建Graph</li></ul></li><li><p><strong>Denoising autoencoder</strong>：</p> <div align="center"><p> <img src="/img/DeepST/2.png" alt="Generalization"></p> </div></li><li><p><strong>Variational graph autoencoder</strong>(VAE)：</p> <div align="center"><p> <img src="/img/DeepST/3.png" alt="Generalization"></p> </div></li><li><p><strong>Domain adversarial neural networks</strong>:</p><ul><li>目的：DAN的目的是将不同分布的源域和目标域映射到同一特征空间，使空间中的距离尽可能接近。</li></ul> <div align="center"><p> <img src="/img/DeepST/4.png" alt="Generalization"></p> </div></li></ol></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>STAGATE</title>
      <link href="/2025/09/20/STAGATE/"/>
      <url>/2025/09/20/STAGATE/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="STAGATE"><a href="#STAGATE" class="headerlink" title="STAGATE"></a>STAGATE</h2><ul><li><strong>标题</strong>：Deciphering spatial domains from spatially resolved transcriptomics with an adaptive graph attention auto-encoder</li><li><strong>作者</strong>：University of Chinese Academy of Sciences</li><li><strong>发表会议&#x2F;期刊</strong>：Nature Communications</li><li><strong>年份</strong>：2022</li><li><strong>链接</strong>：<a href="https://www.nature.com/articles/s41467-022-29439-6">STAGATE</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><strong>Motivation</strong>: 邻域相似性是预定义的，无法自适应学习。</li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><p><strong>总体框架</strong>：</p>  <div align="center"><p>  <img src="/img/STAGATE/0.png" alt="Generalization"></p>  </div></li><li><p>方法概述：</p><ol><li><p>Construction of SNN (Construction of cell type-aware SNN (optional))</p></li><li><p>Graph attention auto-encoder</p><ul><li>Encoder</li></ul> <div align="center"><p> <img src="/img/STAGATE/1.png" alt="Generalization"></p> </div><ul><li>Decoder (迭代和encoder相似)</li></ul> <div align="center"><p> <img src="/img/STAGATE/2.png" alt="Generalization"></p> </div><ul><li>graph attention layer</li></ul> <div align="center"><p> <img src="/img/STAGATE/3.png" alt="Generalization"></p> </div><p> -graph attention layer with cell type-aware SNN</p> <div align="center"><p> <img src="/img/STAGATE/4.png" alt="Generalization"></p> </div><ul><li>Loss function</li></ul> <div align="center"><p> <img src="/img/STAGATE/5.png" alt="Generalization"></p> </div></li></ol></li></ul><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ol><li>Clustering based on STAGATE embeddings (mclust || Louvain)</li><li>Spatial trajectory inference</li><li>Identifying differentially expressed genes</li><li>Identification of 3D spatial domains using STAGATE</li></ol><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spatial-MGCN and MAFN details supplement</title>
      <link href="/2025/09/20/Spatial-MGCN/"/>
      <url>/2025/09/20/Spatial-MGCN/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="Spatial-MGCN"><a href="#Spatial-MGCN" class="headerlink" title="Spatial-MGCN"></a>Spatial-MGCN</h2><ul><li><strong>标题</strong>：Spatial-MGCN: a novel multi-view graph convolutional network for identifying spatial domains with attention mechanism</li><li><strong>作者</strong>：Hunan University</li><li><strong>发表会议&#x2F;期刊</strong>：Briefings in Bioinformatics</li><li><strong>年份</strong>：2023</li><li><strong>链接</strong>：<a href="https://academic.oup.com/bib/article/24/5/bbad262/7225995?login=false">Spatial-MGCN</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><p>Motivation：While increasingly computational methods have been developed for spatial domain detection, most of them cannot adaptively learn the complex relationship between gene expression and spatial information, leading to sub-optimal performance.</p></li><li><p>本文可以视作MAFN的“前身”，主要区别可能是特征图和空间图的融合方式和部分模块细节。</p></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><p><strong>总体框架</strong>：</p>  <div align="center"><p>  <img src="/img/Spatial-MGCN/0.png" alt="Generalization"></p>  </div></li><li><p>方法概述：</p>  <div align="center"><p>  <img src="/img/Spatial-MGCN/1.png" alt="Generalization"><br>  <img src="/img/Spatial-MGCN/2.png" alt="Generalization"><br>  <img src="/img/Spatial-MGCN/3.png" alt="Generalization"><br>  <img src="/img/Spatial-MGCN/4.png" alt="Generalization"><br>  <img src="/img/Spatial-MGCN/5.png" alt="Generalization"></p>  </div></li></ul><h2 id="MAFN细节补充"><a href="#MAFN细节补充" class="headerlink" title="MAFN细节补充"></a>MAFN细节补充</h2><ul><li><p>方法概述：</p>  <div align="center"><p>  <img src="/img/MAFN/a.png" alt="Generalization"><br>  <img src="/img/MAFN/b.png" alt="Generalization"><br>  <img src="/img/MAFN/c.png" alt="Generalization"><br>  <img src="/img/MAFN/d.png" alt="Generalization"><br>  <img src="/img/MAFN/e.png" alt="Generalization"></p>  </div></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>STMGraph</title>
      <link href="/2025/09/17/STMGraph/"/>
      <url>/2025/09/17/STMGraph/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h1><h2 id="STMGraph"><a href="#STMGraph" class="headerlink" title="STMGraph"></a>STMGraph</h2><ul><li><strong>标题</strong>：STMGraph: spatial-context-aware of transcriptomes via a dual-remasked dynamic graph attention model</li><li><strong>作者</strong>：Fujian Agriculture and Forestry University</li><li><strong>发表会议&#x2F;期刊</strong>：Briefings in Bioinformatics</li><li><strong>年份</strong>：2025</li><li><strong>链接</strong>：<a href="https://academic.oup.com/bib/article/26/1/bbae685/7943385">STMGraph</a></li></ul><h2 id="主要内容简介"><a href="#主要内容简介" class="headerlink" title="主要内容简介"></a>主要内容简介</h2><ul><li><p>Motivation：the current ST integration algorithm ignores for ST dropouts, which impedes the spatial-aware of ST features, resulting in challenges in the accuracy and robustness of microenvironmental heterogeneity detecting, spatial domain clustering, and batch-effects correction.</p></li><li><p>现有ST域聚类方法分类：生成式(generative)图自监督学习（Graph SSL）和对比式(contrastive)图自监督学习</p><table><thead><tr><th>方法类别</th><th>代表方法</th></tr></thead><tbody><tr><td>Generative Graph SSL</td><td>DeepST, STAGATE, Spatial-MGCN</td></tr><tr><td>Contrastive Graph SSL</td><td>GraphST, conST, SpaceFlow</td></tr></tbody></table></li></ul><h2 id="方法与创新点"><a href="#方法与创新点" class="headerlink" title="方法与创新点"></a>方法与创新点</h2><ul><li><p><strong>总体框架</strong>：</p>  <div align="center"><p>  <img src="/img/STMGraph/0.png" alt="Generalization"></p>  </div></li><li><p>方法概述：</p><ol><li>Mask-Remask Mechanism</li><li>Dynamic graph attention model(DGAT)</li><li>Dual-View Remask</li><li>Loss function</li></ol>  <div align="center"><p>  <img src="/img/STMGraph/1.png" alt="loss"></p>  </div></li></ul><h2 id="个人评价与思考"><a href="#个人评价与思考" class="headerlink" title="个人评价与思考"></a>个人评价与思考</h2><ul><li>启发：<ol><li>随机掩蔽50%节点模拟真实ST数据中的dropout事件，迫使模型学习在部分特征缺失下的推理能力。</li><li>对编码器输出嵌入H进行二次随机掩蔽（50%），进一步破坏特征，迫使解码器从更抽象的表示中重建原始数据，增强嵌入的鲁棒性和泛化性。</li></ol></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于代码理解MAFN</title>
      <link href="/2025/09/11/MAFN/"/>
      <url>/2025/09/11/MAFN/</url>
      
        <content type="html"><![CDATA[<h1 id="📖-论文阅读记录"><a href="#📖-论文阅读记录" class="headerlink" title="📖 论文阅读记录"></a>📖 论文阅读记录</h1><h2 id="1-基本信息"><a href="#1-基本信息" class="headerlink" title="1. 基本信息"></a>1. 基本信息</h2><ul><li><strong>论文题目</strong>：Multi-View Adaptive Fusion Network for Spatially Resolved Transcriptomics Data Clustering</li><li><strong>作者&#x2F;机构</strong>：China University of Geosciences</li><li><strong>会议&#x2F;期刊</strong>：IEEE TRANSACTIONS</li><li><strong>年份</strong>：DECEMBER 2024</li><li><strong>论文链接</strong>：<a href="https://ieeexplore.ieee.org/document/10648721">MAFN_IEEE</a></li></ul><div style="width:100%; height:6px; background-color: #4CAF50; margin:24px 0;"></div><h2 id="2-方法总览"><a href="#2-方法总览" class="headerlink" title="2. 方法总览"></a>2. 方法总览</h2><ul><li><p><strong>总体框架</strong>：  </p><div align="center"><p><img src="/img/MAFN/1.png" alt="img">  </p></div></li><li><p><strong>关键技术路线</strong>：  </p><ul><li><strong>spatial graph G1(euclidean distance &amp; r), feature graph G2(cosine similarity &amp; kNN)</strong></li><li><strong>Inter-View Complementary Features Learning (GCN)</strong></li><li><strong>Intra-View Discriminative Features Learning(GCN + Lc –&gt; (S-I)^2)</strong></li><li><strong>Cross-View Attention Module (CAM)</strong></li><li><strong>Gene Domain Distribution Constraints</strong><ul><li><p>正则化损失公式Lr：</p><p>$$<br>L_R &#x3D; - \sum_{i&#x3D;1}^N \left( \sum_{j \in R_i} \log(\sigma(H_{ij})) + \sum_{k \notin R_i} \log(1 - \sigma(H_{ik})) \right)<br>$$</p></li><li><p>ZINB分布损失公式Lz：</p><p>$$<br>L_Z &#x3D; -\frac{1}{m(n_s + n_t)} \sum_{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{n_s + n_t} \ln, p_{ZINB}(x_{ij} \mid b_i)<br>$$</p></li></ul></li><li><strong>Overall Loss Function</strong>：<br>  $$<br>  L &#x3D; \lambda_1 L_C + \lambda_2 L_R + \lambda_3 L_Z<br>  $$</li></ul></li></ul><div style="width:100%; height:6px; background-color: #2f6eebff; margin:24px 0;"></div><h2 id="3-代码细节"><a href="#3-代码细节" class="headerlink" title="3. 代码细节"></a>3. 代码细节</h2><ul><li><strong>代码仓库</strong>： <a href="https://github.com/zhubbbzhu/MAFN">MAFN_GitHub</a></li><li><strong>复现细节</strong>（可以用Spatial-MGCN仓库的readme.md作为复现参考）：<ul><li><p><strong>数据下载</strong>：以DLPFC-151507切片为例，下载数据并解压到<code>data</code>文件夹下（可在Spatial-MGCN仓库中找到数据,官方数据集下载地址我没去找QAQ）</p></li><li><p><strong>运行DLPFC_generate_data.py</strong>：对原始数据进行处理，存储为Anndata格式，构建G1和G2(运用utils.py中的函数)</p><ul><li><strong>知识点</strong>：<ul><li><strong>AnnData 结构表格</strong></li></ul></li></ul><table><thead><tr><th>字段</th><th>数据类型</th><th>维度 &#x2F; 形状</th><th>作用 &#x2F; 描述</th><th>示例</th></tr></thead><tbody><tr><td><strong>X</strong></td><td>ndarray &#x2F; sparse</td><td>(n_cells × n_genes)</td><td>存储每个细胞的基因表达矩阵</td><td>原始 counts 或归一化后的表达</td></tr><tr><td><strong>obs</strong></td><td>DataFrame</td><td>(n_cells × n_obs)</td><td>细胞注释信息，每行对应一个细胞</td><td>cell_type, batch, cluster_label</td></tr><tr><td><strong>var</strong></td><td>DataFrame</td><td>(n_genes × n_var)</td><td>基因注释信息，每行对应一个基因</td><td>gene_symbol, highly_variable</td></tr><tr><td><strong>obsm</strong></td><td>dict &#x2F; ndarray</td><td>(n_cells × k)</td><td>细胞低维表示或嵌入向量</td><td>PCA, UMAP, tSNE, 自定义 embedding (<code>mean</code>)</td></tr><tr><td><strong>varm</strong></td><td>dict &#x2F; ndarray</td><td>(n_genes × k)</td><td>基因低维表示或载荷</td><td>PCA loadings</td></tr><tr><td><strong>layers</strong></td><td>dict &#x2F; ndarray</td><td>(n_cells × n_genes)</td><td>多层表达矩阵</td><td>raw counts, normalized, denoised</td></tr><tr><td><strong>obsp</strong></td><td>dict &#x2F; sparse</td><td>(n_cells × n_cells)</td><td>细胞-细胞稀疏矩阵</td><td>kNN 图的 connectivities, distances</td></tr><tr><td><strong>varp</strong></td><td>dict &#x2F; sparse</td><td>(n_genes × n_genes)</td><td>基因-基因稀疏矩阵（可选，较少用）</td><td>PCA 基因相似性矩阵</td></tr><tr><td><strong>uns</strong></td><td>dict</td><td>无固定形状</td><td>无结构结果或其他参数</td><td>colors, neighbors params, pca info</td></tr></tbody></table><ul><li><strong>notice</strong>:<ul><li>我将源码里os.mkdir改成了os.makedirs，防止文件缺失报错</li></ul></li></ul></li><li><p><strong>运行DLPFC_test.py</strong>:<br>-<strong>note</strong>:<br>- ZINB分布损失，需要三个参数：mean,disp,pi 均是通过models&#x2F;decoder得到  </p>  <div align="center"><p>  <img src="/img/MAFN/3.png" alt="3">  </p>  </div></li><li><p><strong>结果</strong>:</p><ul><li><p><strong>训练ing</strong>:</p><div align="center"><p><img src="/img/MAFN/4.png" alt="4">  </p></div></li><li><p><strong>可视化</strong>:</p><ul><li><strong>左图为手动标注的细胞类型，右图为MAFN聚类结果</strong></li></ul><div style="display: flex; justify-content: space-between; gap: 16px;">  <img src="/img/MAFN/Manual_Annotation.jpg" alt="手动标注" style="width: 48%;" />  <img src="/img/MAFN/MAFN.jpg" alt="MAFN聚类" style="width: 48%;" /></div><ul><li><strong>UMAP和PAGA可视化</strong></li></ul><div style="display: flex; justify-content: flex-start;">  <img src="/img/MAFN/MAFN_umap_mean.jpg" alt="UMAP和PAGA" style="width: 60%;" /></div><ul><li><strong>MAFN聚类标签和embedding representation</strong></li></ul><div style="display: flex; justify-content: space-between; gap: 16px;">  <img src="/img/MAFN/5.png" alt="聚类标签" style="width: 48%;" />  <img src="/img/MAFN/6.png" alt="embedding" style="width: 48%;" /></div></li></ul></li></ul></li></ul><div style="width:100%; height:6px; background-color: #d43aecff; margin:24px 0;"></div><h2 id="4-Summary"><a href="#4-Summary" class="headerlink" title="4.Summary"></a>4.Summary</h2><ul><li>熟悉Scanpy，单细胞数据集，Anndata数据结构</li><li>umap可视化 and so on…</li></ul><div style="width:100%; height:6px; background-color: #e47d23ff; margin:24px 0;"></div><h2 id="5-References"><a href="#5-References" class="headerlink" title="5. References"></a>5. References</h2><ul><li><a href="https://pubmed.ncbi.nlm.nih.gov/37466210/">Spatial-MGCN</a>  </li><li><a href="https://cdn.aaai.org/ojs/20392/20392-13-24405-1-2-20220628.pdf">scTAG</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Fusion Clustering Network</title>
      <link href="/2025/09/08/DFCN/"/>
      <url>/2025/09/08/DFCN/</url>
      
        <content type="html"><![CDATA[<h1 id="📖-论文阅读记录"><a href="#📖-论文阅读记录" class="headerlink" title="📖 论文阅读记录"></a>📖 论文阅读记录</h1><h2 id="1-基本信息"><a href="#1-基本信息" class="headerlink" title="1. 基本信息"></a>1. 基本信息</h2><ul><li><strong>论文题目</strong>：Deep Fusion Clustering Network</li><li><strong>作者&#x2F;机构</strong>：National University of Defense Technology</li><li><strong>会议&#x2F;期刊</strong>：AAAI</li><li><strong>年份</strong>：2021</li></ul><!-- - **论文链接**： [PDF/Arxiv](https://example.com)   --><hr><h2 id="2-研究背景"><a href="#2-研究背景" class="headerlink" title="2. 研究背景"></a>2. 研究背景</h2><ul><li>研究领域：深度聚类</li><li>主要问题：  <ol><li>缺乏动态融合机制来选择性整合和精炼图结构与节点属性的信息以达成共识表示学习；</li><li>未能从双方提取信息以生成鲁棒的目标分布（即“真实”软标签）。</li></ol></li><li>相关工作：  <ol><li>属性图聚类</li><li>目标分布生成</li></ol></li></ul><hr><h2 id="3-核心贡献"><a href="#3-核心贡献" class="headerlink" title="3. 核心贡献"></a>3. 核心贡献</h2><ul><li>✨ 创新点：通过SAIF模块实现AE与IGAE的特征深度融合</li></ul><hr><h2 id="4-方法"><a href="#4-方法" class="headerlink" title="4. 方法"></a>4. 方法</h2><ul><li><strong>SAIF总体框架</strong>：</li></ul><div align="center"><p><img src="/img/DFCN/0.png" alt="framework"></p></div><ul><li><strong>标号</strong>：</li></ul><div align="center"><p><img src="/img/DFCN/2.png" alt="notation"></p></div><ul><li><strong>Fusion-based Autoencoders</strong></li></ul><br><div align="center"><p><img src="/img/DFCN/6.png" alt="notation"></p></div><ul><li><strong>Structure and Attribute Information Fusion</strong></li></ul><br><div align="center"><p><img src="/img/DFCN/7.png" alt="notation"><br><img src="/img/DFCN/8.png" alt="notation"></p></div><ul><li><strong>Joint loss and Optimization</strong></li></ul><div align="center"><p><img src="/img/DFCN/5.png" alt="notation"></p></div><hr><h2 id="5-实验"><a href="#5-实验" class="headerlink" title="5. 实验"></a>5. 实验</h2><ul><li>数据集：  三个图数据集（ACM、DBLP、CITE）和三个非图数据集（USPS、HHAR、REUT）</li><li>评价指标： 准确率（ACC）、归一化互信息（NMI）、平均兰德指数（ARI）和宏观F1分数（F1）</li></ul><hr><!-- ## 6. 总结与评价- 👍 优点：  - 👎 局限性：  - 💡 可以改进的地方：  ---## 7. 个人思考- 与我研究/兴趣的联系：  - 可以借鉴的思路：  - 疑问：  --- --><!-- ## 8. 参考资料 --><!-- - [相关论文1]()   --><!-- - [相关论文2]()   -->]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单细胞算法典型任务</title>
      <link href="/2025/09/08/Single-Cell_Task/"/>
      <url>/2025/09/08/Single-Cell_Task/</url>
      
        <content type="html"><![CDATA[<h1 id="📖-论文阅读记录"><a href="#📖-论文阅读记录" class="headerlink" title="📖 论文阅读记录"></a>📖 论文阅读记录</h1><h2 id="TASK"><a href="#TASK" class="headerlink" title="TASK"></a>TASK</h2><div align="center"><p><img src="/img/Single-Cell_Task/1.png" alt="task"></p></div>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bio-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为你写诗</title>
      <link href="/2025/06/07/%E4%B8%BA%E4%BD%A0%E5%86%99%E8%AF%97/"/>
      <url>/2025/06/07/%E4%B8%BA%E4%BD%A0%E5%86%99%E8%AF%97/</url>
      
        <content type="html"><![CDATA[<!-- 专栏引言 --><div align="center" style="margin: 24px 0;">  <span style="display:inline-block; color:#2E86C1; font-size:1.3em; font-weight:bold; letter-spacing:2px; border-bottom:2px solid #2E86C1; padding:4px 12px; background:rgba(232,244,253,0.85); border-radius:8px;">    情绪是人类最美的意境  </span></div><!-- 第一首诗 --><h3 style="color:#AF601A;">寻梦</h3><p><sub style="color:#5499C7;">写于 2020 年 1 月 24 日 1:34</sub></p><p align="center" style="color:#2C3E50; font-size:1.1em; line-height:1.8;"><p><span style="color:#48C9B0;">我一生都在你梦中穿行</span></p><span style="color:#7B7D7D;"><p>不禁喜欢你的座位<br>常从你座位经过<br>一支笔、一本书或一块橡皮擦<br>都是我着迷的对象<br>幻想着它们在你手中旋转<br>陪你度过一个又一个季节  </p></span><span style="color:#5DADE2;"><p>喜欢追寻你的脚步<br>领略你所欣赏过的风景<br>从学校、商场到车站、广场<br>凡是你走过的路<br>我都会驻足留连<br>我会看到你的影子<br>我会嗅到你的笑意<br>我会捕捉到你眉眼间的秀气  </p></span><span style="color:#D35400;"><p>我追寻着你的踪迹<br>像在寻梦<br>甜美的 梦幻的<br>独一无二的梦  </p></span><span style="color:#48C9B0;"><p>我一生都在你梦中穿行<br>只为给你编织一个美好的梦境</p></span></p><!-- --- --><!-- 第二首诗<h3 style="color:#6C3483;">诗歌标题二</h3><sub style="color:#B7950B;">写于 2024 年 6 月 8 日</sub><p align="center" style="color:#34495E; font-size:1.1em; line-height:1.8;">第二首诗的内容  第二行  第三行  </p>---可以继续添加更多诗歌，格式同上 -->]]></content>
      
      
      <categories>
          
          <category> 为你写诗 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> poetry </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>打卡</title>
      <link href="/2025/06/05/%E6%89%93%E5%8D%A1/"/>
      <url>/2025/06/05/%E6%89%93%E5%8D%A1/</url>
      
        <content type="html"><![CDATA[<h2 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h2><blockquote><p>岁月在默数三四五六，第六天以后</p></blockquote><div align="center"><p><img src="/img/punch/day1.jpg" alt="breakfast"></p></div><h2 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h2><blockquote><p>情绪是人类最美的意境</p></blockquote><div align="center"><p><img src="/img/punch/day2.jpg" alt="study"></p></div><h2 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h2><blockquote><p>花费在热爱上，怎么可能会是浪费</p></blockquote><div align="center"><p><img src="/img/punch/day3.jpg" alt="study"></p></div><h2 id="Day-4"><a href="#Day-4" class="headerlink" title="Day 4"></a>Day 4</h2><blockquote><p>区区三万天，试试又能怎</p></blockquote><div align="center"><p><img src="/img/punch/day4.jpg" alt="breakfast"></p></div><h2 id="Day-5"><a href="#Day-5" class="headerlink" title="Day 5"></a>Day 5</h2><blockquote><p>渐变黑莲花</p></blockquote><div align="center"><p><img src="/img/punch/day5.jpg" alt="breakfast"></p></div><h2 id="Failure-1"><a href="#Failure-1" class="headerlink" title="Failure 1"></a>Failure 1</h2><blockquote><p>天禄是回家的路</p></blockquote><div align="center"><p><img src="/img/punch/failure1.jpg" alt="breakfast"></p></div><h2 id="day-6"><a href="#day-6" class="headerlink" title="day 6"></a>day 6</h2><blockquote><p>没有人能投进每颗绝杀球</p></blockquote><div align="center"><p><img src="/img/punch/day6.jpg" alt="breakfast"></p></div>]]></content>
      
      
      <categories>
          
          <category> Daily </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Paul George</title>
      <link href="/2025/06/04/Paul-George/"/>
      <url>/2025/06/04/Paul-George/</url>
      
        <content type="html"><![CDATA[<h1 id="保罗·乔治"><a href="#保罗·乔治" class="headerlink" title="保罗·乔治"></a>保罗·乔治</h1><blockquote><p>“巅峰诞生虚伪的拥护，黄昏见证虔诚的信徒。”  </p><div align="right">——题记</div></blockquote><p>这是我追过最好的青春。</p><p>如果 NBA 是一部引人入胜的小说，那注定会有人成为主角，有人成为配角。而我喜欢的球星，就远不如詹姆斯、科比那般耀眼，且自认是球队的二把手。但那又如何呢？我就是喜欢那个相对平凡但从未放弃的保罗·乔治。</p><p>他被称为“NBA 背景板”，因为他生涯被绝杀 12 次，其中七次还是乔治主防的，这些数据位列联盟现役第一。由此看来，他似乎就是那个配角，用以衬托那些超级巨星。他就像文言文中毫无实义、不用翻译的语气词；也像圆锥曲线大题里可以忽略、照搬答案的第一问；更像《云顶之弈》中站在角落里凑羁绊的亚托克斯，而拿到绝杀的球星则是那众星拱月、戴着“群英冠冕”的佐伊。</p><p>话说回来，我热爱乔治的原因并不是他作为背景板，而是他涅槃重生的故事。</p><p>2014 年，美国梦之队在拉斯维加斯进行的一场队内训练赛中，乔治在追防哈登后，不慎撞向篮架，造成小腿 90 度骨折，令在场所有人惋惜。对于一个篮球运动员来说，这种伤病是致命的，很可能会结束自己的整个篮球生涯。但出乎所有人的意料，八个月后，他重返赛场，只是球衣号码从 24 号变到了 13 号——他还是他。</p><p>即使运动能力有所下降，他也不曾一蹶不振。后来，他离开了步行者，先是在雷霆队与威少组成了雷霆双子星。在那里，他似乎找回了自己，于 19 年成为了那个赛季的绝杀王，并且进入双一阵。之后，他被交易到快船，与刚刚带领猛龙队拿下总冠军的伦纳德联合，组成“卡椒组合”。（伦纳德 Kawhi Leonard，“小卡”；乔治 Paul George，“泡椒”）</p><p>20-21 赛季，在小卡缺席的情况下，他一人带领快船队这只“小破船”杀到了西部决赛，但无奈止步于西决。如今他仍在快船队，而本赛季小卡正式回归，卡椒组合也不负众望多次配合赢下比赛。</p><blockquote><p>“断过小腿，但从未断过涅槃重生的信念。”</p></blockquote><p>乔治无法回到受伤前，只能带着已在小腿里八年之久的钢板负重前行。没人知道他是怎么熬过那断腿的八个月和之后的八年的，只有他自己心里清楚恢复的艰难和背后的辛酸。许多球迷在他断腿后便离他而去——人们就是这样，总青睐于那些耀眼的数据、漂亮的动作，却厌恶极了不慎的失误、糟糕的表现。准确地讲，他们喜欢的是乔治的球技，而不是乔治本身。但在我看来，乔治的精神才是我热爱的根源。他的乐观、坚韧和顽强无一不成为了我每个晚自习奋斗的力量。</p><blockquote><p>“海压竹枝低复举，风吹山脚晦还明。”</p></blockquote><p>我见证过你的巅峰与黄昏，也听闻过你的涅槃重生。现在，我只是等待着你，冲进总决赛，举起那该死的奥布莱恩杯。</p><p>那时，印第安纳的河水逆流而上，年轻的将军意气风发。</p>]]></content>
      
      
      <categories>
          
          <category> Writing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
